# GCP Event-Driven Architecture, CI/CD Deployment, and Airflow DAG

Este repositorio contiene la soluciÃ³n a tres ejercicios prÃ¡cticos relacionados con arquitecturas orientadas a eventos en Google Cloud Platform (GCP), despliegue automatizado de funciones mediante CI/CD, y procesamiento de datos con Airflow.

## ğŸ§© 1. Arquitectura orientada a eventos

Define una arquitectura orientada a eventos, en donde al recibir un archivo en un bucket este se procese.

**DescripciÃ³n de la soluciÃ³n:**  
- Se utiliza **Cloud Storage** como punto de entrada (evento: carga de archivo).
- La carga de un archivo en el bucket dispara una **Cloud Function** (`cloud_function/main.py`).
- La funciÃ³n procesa el archivo segÃºn la lÃ³gica deseada.

**Diagrama conceptual:**
Usuario o sistema externo
â”‚
Subida de archivo
a Bucket
â”‚
Cloud Function (trigger: finalize/create)
â”‚
Procesamiento del archivo

---

## ğŸš€ 2. CI/CD con GitHub Actions + Terraform

Desarrolle un pipeline de GitHub que despliegue una Cloud Function a travÃ©s de Terraform.

**DescripciÃ³n de la soluciÃ³n:**  
- Se utiliza **GitHub Actions** como plataforma de CI/CD (`.github/workflows/deploy_cloud_function.yml`).
- El pipeline ejecuta Terraform para desplegar una Cloud Function con el cÃ³digo actualizado.

**Comandos claves del pipeline:**

- name: Terraform Init
  run: terraform init

- name: Terraform Apply
  run: terraform apply -auto-approve

## ğŸ—ƒï¸ **3. DAG de Airflow: carga desde GCS a BigQuery**

Construya un DAG de Airflow que utilice operadores nativos para tomar un archivo desde un bucket e inserte en BigQuery, posteriormente ejecutar una query.

DescripciÃ³n de la soluciÃ³n:

DAG ubicado en dags/gcs_to_bq_dag.py.

Usa operadores nativos de Airflow:

GCSToBigQueryOperator para cargar datos.

BigQueryInsertJobOperator para ejecutar una consulta SQL posterior.

Programado para ejecutarse diariamente o manualmente.

Pasos del DAG:

1. Toma archivo desde un bucket (GCS)
2. Inserta en una tabla de BigQuery
3. Ejecuta una query analÃ­tica sobre esa tabla

Nota: Se utiliza **GitHub Actions** como plataforma de CI/CD (`.github/workflows/deploy-dag.yml`). 

## ğŸš€ **4. Arquitectura de Datos**

a. Preguntas a las Ã¡reas de negocio
1.	Â¿CuÃ¡l es la prioridad de contacto?
o	Â¿Hay clientes que deben ser contactados antes que otros? (ej. por urgencia, valor del cliente).
2.	Â¿CuÃ¡l es la tolerancia a la latencia?
o	Â¿Se espera que los clientes sean contactados inmediatamente o se pueden contactar dentro de una ventana de tiempo razonable?
3.	Â¿QuÃ© debe ocurrir si un intento de llamada falla?
o	Â¿Se reintenta? Â¿CuÃ¡ntas veces? Â¿Con quÃ© intervalo?
4.	Â¿QuÃ© datos del cliente se deben enviar a la API?
o	TelÃ©fono, nombre, cÃ³digo de campaÃ±a, tipo de producto, etc.
5.	Â¿QuÃ© se espera como resultado?
o	Â¿La llamada debe completarse? Â¿Solo se necesita agendar? Â¿Debe capturar respuesta?
6.	Â¿Existen horarios o dÃ­as hÃ¡biles en los que se puede llamar?
o	Â¿Se deben restringir llamadas por horarios?
________________________________________
b. Preguntas al proveedor de la API
1.	Â¿La API tiene alguna documentaciÃ³n?
2.	Â¿CuÃ¡l es el mÃ©todo de autenticaciÃ³n requerido?
o	API Key, OAuth2, JWT, etc.
2.	Â¿QuÃ© ocurre si se excede el lÃ­mite de 10 requests/segundo?
o	Â¿La API responde con 429 (Too Many Requests)? Â¿Hay backoff sugerido?
3.	Â¿Soporta procesamiento asÃ­ncrono?
o	Â¿Existe un endpoint para enviar lote y luego consultar resultados?
4.	Â¿QuÃ© tipo de respuesta devuelve la API?
o	Â¿Formato JSON? Â¿Incluye estados de llamada?
5.	Â¿Existe una polÃ­tica de reintentos recomendada?
o	Â¿CuÃ¡ntas veces, con quÃ© intervalo?
6.	Â¿Existe un sandbox o entorno de pruebas?
o	Para hacer pruebas sin impacto en producciÃ³n.
7.	Â¿Tienen SLA definidos para disponibilidad de la API?
________________________________________
c. Arquitectura propuesta en GCP
DescripciÃ³n general
Necesitamos enviar en promedio 600 llamadas por hora = 10 por minuto = ~1 cada 6 segundos, lo que estÃ¡ muy por debajo del lÃ­mite de 10 rps.
Para garantizar cumplimiento, escalabilidad y tolerancia a errores, usaremos:
Componentes
â€¢	Cloud Scheduler: para lanzar el proceso de llamadas cada minuto.
â€¢	Cloud Function (o Cloud Run): para procesar los lotes y enviar las llamadas.
â€¢	Cloud Tasks: para controlar el rate limit y reintentos.
â€¢	Cloud Logging + BigQuery: para trazabilidad.
________________________________________
Diagrama
En archivo diagrama.png

________________________________________
d. JustificaciÃ³n de la arquitectura
1.	Escalabilidad controlada:
o	Cloud Tasks permite controlar el nÃºmero de ejecuciones concurrentes y el rate (configurable), cumpliendo los 10 rps mÃ¡ximos.
2.	Tolerancia a fallos y reintentos:
o	Cloud Tasks ofrece reintentos automÃ¡ticos con backoff exponencial.
3.	Desacoplamiento y modularidad:
o	Scheduler se encarga del disparo periÃ³dico.
o	La lÃ³gica de envÃ­o estÃ¡ encapsulada y puede evolucionar sin afectar la programaciÃ³n.
4.	Costos bajos:
o	Todos los servicios son serverless y con bajo costo en bajo volumen.
5.	AuditorÃ­a y monitoreo:
o	Se puede enviar a BigQuery o Cloud Logging la traza de cada intento con resultado (Ã©xito/fallo).
6.	Cumplimiento de reglas de negocio:
o	Se puede implementar lÃ³gica para horarios, filtros, prioridad, etc.


